{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Interpreting a Random Forest Model with LIME\n",
        "### A Demonstration for Federal Government AI Professionals\n",
        "\n",
        "In this notebook, we will:\n",
        "1. Install and import [**LIME**](https://github.com/marcotcr/lime), a popular library for model interpretability.\n",
        "2. Load the **Boston Housing** dataset from a **new URL**.\n",
        "3. Train a **Random Forest** regressor to predict housing prices.\n",
        "4. Use **LIME** to explain the predictions of specific instances.\n",
        "\n",
        "> **Why it matters**: Federal agencies often require interpretable models to ensure fairness, transparency, and accountability in decision-making processes. Whether you’re working on a housing grants project or any other high-stakes federal program, LIME can help you provide clear explanations to policymakers and stakeholders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install-lime"
      },
      "source": [
        "## 1. Install LIME (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pip-lime"
      },
      "source": [
        "!pip install lime --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "## 2. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports-code"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# LIME\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-load"
      },
      "source": [
        "## 3. Load the Dataset\n",
        "\n",
        "We'll pull the Boston Housing dataset from GitHub (hosted by [Selva Prabhakaran](https://github.com/selva86/datasets/)).\n",
        "\n",
        "> **Note**: The original code attempted to load a `.pkl` file from a URL that’s no longer valid. Here, we’ve switched to a CSV-based version of the dataset for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "data-load-code"
      },
      "source": [
        "# New URL for the Boston Housing CSV\n",
        "url = 'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'\n",
        "\n",
        "# Fetch the data\n",
        "response = requests.get(url)\n",
        "data_as_string = response.content.decode('utf-8')\n",
        "\n",
        "# Read into a pandas DataFrame\n",
        "housing_df = pd.read_csv(pd.io.common.StringIO(data_as_string))\n",
        "\n",
        "print(\"Data loaded successfully!\")\n",
        "housing_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "explore-data"
      },
      "source": [
        "### Quick Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "explore-data-code"
      },
      "source": [
        "# Summary stats\n",
        "housing_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "features-target"
      },
      "source": [
        "## 4. Define Features and Target\n",
        "\n",
        "The dataset columns:\n",
        "- `medv` is the median home value (our **target**).\n",
        "- All other columns are **features**.\n",
        "\n",
        "For this demo, we use all features, but in a real Federal agency scenario, you might select features aligned with policy or domain constraints (e.g., focusing on geospatial, demographic, or environmental attributes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "train-test-split-code"
      },
      "source": [
        "# Separate features (X) and target (y)\n",
        "X = housing_df.drop('medv', axis=1)\n",
        "y = housing_df['medv']\n",
        "\n",
        "# We will store feature names for LIME\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-rf"
      },
      "source": [
        "## 5. Train a Random Forest Model\n",
        "\n",
        "Random Forest is a popular ensemble method that often works well out-of-the-box. After training, we can interpret individual predictions using LIME."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf-code"
      },
      "source": [
        "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "train_score = regressor.score(X_train, y_train)\n",
        "test_score = regressor.score(X_test, y_test)\n",
        "\n",
        "print(f\"Random Forest Training R^2 Score: {train_score:.3f}\")\n",
        "print(f\"Random Forest Test R^2 Score: {test_score:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lime-intro"
      },
      "source": [
        "## 6. Interpreting Predictions with LIME\n",
        "\n",
        "[**LIME**](https://github.com/marcotcr/lime) stands for **Local Interpretable Model-agnostic Explanations**. It explains individual predictions by approximating the complex model locally (near the instance you want to explain) with a simpler model (like a linear model).\n",
        "\n",
        "### Defining Categorical Features\n",
        "In some Federal use-cases, you may have a mix of numeric and categorical data. For demonstration, let’s assume `chas` (Charles River dummy variable) is categorical:\n",
        "- `chas` = 1 if the property bounds the river; 0 otherwise.\n",
        "\n",
        "In the Boston dataset, that’s the 4th column (0-indexed = 3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cat-code"
      },
      "source": [
        "# Let's identify categorical columns for LIME\n",
        "cat_cols = [3]  # 'chas' column\n",
        "\n",
        "explainer = LimeTabularExplainer(\n",
        "    training_data=np.array(X_train),\n",
        "    feature_names=feature_names,\n",
        "    categorical_features=cat_cols,\n",
        "    mode='regression'\n",
        ")\n",
        "print(\"LIME explainer initialized!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example-lime"
      },
      "source": [
        "### 6.1 Explain a Single Instance\n",
        "We will select an instance (say, index=10 in our test set) and explain the Random Forest’s predicted price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lime-example-code"
      },
      "source": [
        "instance_idx = 10  # pick an index from the test set\n",
        "\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=X_test.iloc[instance_idx],\n",
        "    predict_fn=regressor.predict,\n",
        "    num_features=8\n",
        ")\n",
        "\n",
        "fig = exp.as_pyplot_figure()\n",
        "plt.title(f\"LIME Explanation for Test Instance #{instance_idx}\")\n",
        "plt.show()\n",
        "\n",
        "exp_list = exp.as_list()\n",
        "print(\"\\nExplanation as list of (feature, effect):\")\n",
        "for feature, val in exp_list:\n",
        "    print(f\"{feature} => {val:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "multi-explanations"
      },
      "source": [
        "### 6.2 Compare Explanations for Multiple Instances\n",
        "For a better understanding, let’s compare explanations for two more instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lime-compare-code"
      },
      "source": [
        "instances_to_explain = [5, 25]  # you can pick any two test indices\n",
        "\n",
        "for i in instances_to_explain:\n",
        "    exp = explainer.explain_instance(\n",
        "        data_row=X_test.iloc[i],\n",
        "        predict_fn=regressor.predict,\n",
        "        num_features=8\n",
        "    )\n",
        "    fig = exp.as_pyplot_figure()\n",
        "    plt.title(f\"LIME Explanation for Test Instance #{i}\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "You have just seen how **LIME** can help Federal Government AI professionals—and really anyone—explain the predictions of complex models, such as **Random Forest** in this example.\n",
        "\n",
        "In a real-world Federal use-case, such transparency is often required for:\n",
        "- **Policy compliance** (e.g., ensuring no unlawful biases).\n",
        "- **Audit and oversight** by internal or external agencies.\n",
        "- **Stakeholder communication** with leadership and the public.\n",
        "\n",
        "Experiment with different rows, features, and model parameters to see how explanations change. This will help build trust and confidence in your machine learning solutions!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
